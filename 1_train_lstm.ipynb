{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a LSTM to classify yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.process_labels import *\n",
    "from src.data_processing.process_reviews import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data/raw_reviews/reviews_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate reviews and labels\n",
    "reviews = df.text\n",
    "food_labels = df.food\n",
    "service_labels = df.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get review labels\n",
    "Get joint distribution for only food, only service, both food and service, and neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.process_labels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_generator(food_labels=food_labels.values, \n",
    "                    service_labels=service_labels.values).trim_and_fetch_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim reviews to size of labels (y)\n",
    "reviews = reviews[:len(y)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize reviews\n",
    "## seperating the words\n",
    "from src.data_processing.word_tokenizer import basic_tokenizer\n",
    "review_list = [basic_tokenizer(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding reviews\n",
    "## give each token 300 dim vector from word2vec\n",
    "from src.data_processing.word_tokenizer import batch_embedding\n",
    "# Load word2vec model\n",
    "model = KeyedVectors.load('word2vec/word2vec-google-news-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching review embeddings: 100%|██████████| 1000/1000 [00:06<00:00, 143.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# word embeddings for all reviews\n",
    "x_all = batch_embedding(review_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 652, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3770, 0.0660, 0.5300, 0.0270])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class frequences for [food only, service only, both, neither]\n",
    "torch.bincount(torch.argmax(y, dim=1)) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/validate/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.train_val_test import train_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test = train_val_test(x_all, train_frac=0.6, val_frac=0.2, test_frac=0.2)\n",
    "y_train, y_val, y_test = train_val_test(y, train_frac=0.6, val_frac=0.2, test_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([600, 652, 300]), torch.Size([600, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pytorch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch datasets\n",
    "dataset_train, dataset_val, dataset_test = (TensorDataset(x_train, y_train),\n",
    "                                            TensorDataset(x_val, y_val),\n",
    "                                            TensorDataset(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch dataloader\n",
    "dataloader_train, dataloader_val, dataloader_test = (DataLoader(dataset_train, batch_size=1, shuffle=True),\n",
    "                                                     DataLoader(dataset_val, batch_size=1, shuffle=True),\n",
    "                                                     DataLoader(dataset_test, batch_size=1, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_zoo import *\n",
    "from src.models.model_train import *\n",
    "\n",
    "# instatiate model\n",
    "input_size = 300\n",
    "hidden_size = 300\n",
    "num_layers = 2\n",
    "dropout_prob = 0.5\n",
    "output_size = 4\n",
    "lstm_model = LSTMmodel(input_size=input_size, hidden_size=hidden_size, \n",
    "                       output_size=output_size, num_layers=num_layers, dropout_prob=dropout_prob)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   0%|          | 0/50 [04:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "val_one_epoch() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# run training loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_loss_list, val_loss_list \u001b[39m=\u001b[39m training_loop(model\u001b[39m=\u001b[39;49mlstm_model, criterion\u001b[39m=\u001b[39;49mcriterion, \n\u001b[0;32m      3\u001b[0m                                                optimizer\u001b[39m=\u001b[39;49moptimizer, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[0;32m      4\u001b[0m                                                dataloader_train\u001b[39m=\u001b[39;49mdataloader_train, \n\u001b[0;32m      5\u001b[0m                                                dataloader_val\u001b[39m=\u001b[39;49mdataloader_val, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\mattc\\Documents\\yelper-helper\\src\\models\\model_train.py:107\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, criterion, optimizer, patience, dataloader_train, dataloader_val, epochs)\u001b[0m\n\u001b[0;32m    105\u001b[0m train_loss \u001b[39m=\u001b[39m train_one_epoch(model, criterion, optimizer, dataloader_train)\n\u001b[0;32m    106\u001b[0m train_loss_list\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m--> 107\u001b[0m val_loss \u001b[39m=\u001b[39m val_one_epoch(model, criterion, optimizer, dataloader_val)\n\u001b[0;32m    108\u001b[0m val_loss_list\u001b[39m.\u001b[39mappend(val_loss)\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m early_stopper\u001b[39m.\u001b[39mearly_stop(validation_loss\u001b[39m=\u001b[39mval_loss):\n",
      "\u001b[1;31mTypeError\u001b[0m: val_one_epoch() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# run training loop\n",
    "train_loss_list, val_loss_list = training_loop(model=lstm_model, criterion=criterion, \n",
    "                                               optimizer=optimizer, patience=5, \n",
    "                                               dataloader_train=dataloader_train, \n",
    "                                               dataloader_val=dataloader_val, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
