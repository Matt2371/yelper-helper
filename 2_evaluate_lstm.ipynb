{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.process_labels import *\n",
    "from src.data_processing.process_reviews import *\n",
    "from src.data_processing.train_val_test import train_val_test\n",
    "from src.models.model_zoo import *\n",
    "from src.models.model_train import *\n",
    "from src.models.model_evalaute import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in saved LSTM torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_zoo import *\n",
    "from src.models.model_train import *\n",
    "\n",
    "# instatiate model\n",
    "input_size = 300\n",
    "hidden_size = 300\n",
    "num_layers = 2\n",
    "dropout_prob = 0.3\n",
    "output_size = 4\n",
    "lstm_model = LSTMmodel(input_size=input_size, hidden_size=hidden_size, \n",
    "                       output_size=output_size, num_layers=num_layers, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3612004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMmodel(\n",
       "  (LSTM): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (linear): Linear(in_features=600, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved parameters\n",
    "lstm_model.load_state_dict(torch.load('src/models/saved_models/lstm_model.pt'))\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: try made up review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2vec model\n",
    "model = KeyedVectors.load('word2vec/word2vec-google-news-300.model') # Load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching review embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3155, 0.0370, 0.6094, 0.0381]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madeup = ['i liked their pizza']\n",
    "lstm_model(process_reviews_w2v(madeup, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not able to correctly classify any common sense test cases, except for text that are both food and service. Therefore, we now focus on finetuning a BERT model instead of training an LSTM from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching review embeddings: 100%|██████████| 1000/1000 [00:03<00:00, 251.86it/s]\n"
     ]
    }
   ],
   "source": [
    "## PROCESS DATA\n",
    "# Read data\n",
    "df = pd.read_csv('data/raw_reviews/reviews_v1.csv')\n",
    "# Separate reviews and labels\n",
    "reviews = df.text\n",
    "food_labels = df.food\n",
    "service_labels = df.service\n",
    "# Get target labels\n",
    "y = label_generator(food_labels=food_labels.values, \n",
    "                    service_labels=service_labels.values).trim_and_fetch_labels()\n",
    "# Trim reviews to size of labels (y)\n",
    "reviews = reviews[:len(y)].copy()\n",
    "# Get word2vec embedded reviews\n",
    "model = KeyedVectors.load('word2vec/word2vec-google-news-300.model') # Load word2vec model\n",
    "x_all = process_reviews_w2v(reviews=reviews, model=model) # (1000, max review length, 300)\n",
    "x_all = x_all[:, :200, :] # cut reviews to only keep first 200 words\n",
    "# Train/Val/Test split\n",
    "x_train, x_val, x_test = train_val_test(x_all, train_frac=0.6, val_frac=0.2, test_frac=0.2)\n",
    "y_train, y_val, y_test = train_val_test(y, train_frac=0.6, val_frac=0.2, test_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output softmax probabilities for x test\n",
    "y_scores = lstm_model(x_test)\n",
    "\n",
    "# convert to one-hot predicted labels\n",
    "pred_labels = torch.argmax(y_scores, dim=1)\n",
    "y_pred = torch.nn.functional.one_hot(pred_labels, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>only food</th>\n",
       "      <th>only service</th>\n",
       "      <th>both</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          only food only service      both neither\n",
       "f1              0.0          0.0  0.675497     0.0\n",
       "precision       0.0          0.0      0.51     0.0\n",
       "recall          0.0          0.0       1.0     0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get performance metrics\n",
    "classes = ['only food', 'only service', 'both', 'neither']\n",
    "performance_df, accuracy = multi_performance(y_true=y_test, y_pred=y_pred, classes=classes)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy is: 0.51\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall accuracy is: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as csv\n",
    "performance_df.to_csv('results/lstm_performance_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
